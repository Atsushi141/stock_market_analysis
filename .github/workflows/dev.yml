on:
  push:
    branches-ignore:
      - main

# jobs:
#   build-and-test:
#     uses: ./.github/workflows/databricks.yml
#     with:
#       target-gh-env: DEVELOPMENT
#       target-databricks-workspace: dev


jobs:
  test_and_deploy_to_dev:
    name: Test and Deploy to Dev
    runs-on: ubuntu-latest
    environment: DEVELOPMENT

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-pyspark.txt

      - name: Run pytest
        run: |
          pytest

      - name: Databricks CLI Setup
        uses: databricks/setup-cli@main

      - name: Configure Databricks Credentials
        run: |
          cat <<EOF > ~/.databrickscfg
          [dev]
          host = ${{ vars.DATABRICKS_HOST }}
          azure_tenant_id = ${{vars.AZURE_TENANT_ID }}
          azure_client_id = ${{ vars.AZURE_CLIENT_ID }}
          azure_client_secret = ${{ secrets.AZURE_CLIENT_SECRET }}
          EOF

      - name: debug
        run: cat ~/.databrickscfg

      - name: Databricks Bundle Deploy
        run: databricks bundle deploy -t dev -p dev
